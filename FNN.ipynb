{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d47ace34-f3db-451f-9dad-d6a7b6b7e400",
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class Activation(str, Enum):\n",
    "    SIGMOID = \"Sigmoid\"\n",
    "    SOFTMAX = \"Softmax\"\n",
    "    RELU = \"ReLU\"\n",
    "\n",
    "class Loss(str, Enum):\n",
    "    MSE = \"Mean Squared Error \"\n",
    "    CE = \"Cross Entropy\"\n",
    "    \n",
    "class Layer:\n",
    "    def __init__(self, neurons, activation):\n",
    "        self.activation = activation\n",
    "        self.w = None        \n",
    "        self.b = np.random.uniform(low=0, high=1, size=(neurons, 1))\n",
    "        self.z = None\n",
    "        self.a = None\n",
    "        self.delta = []\n",
    "        self.gradient_w= []\n",
    "        self.gradient_b= []\n",
    "        \n",
    "    def neuronsCount(self):\n",
    "        return self.b.size        \n",
    "        \n",
    "class FNN:\n",
    "    def __init__(self, lossFunction, inputs):\n",
    "        self.layers = []\n",
    "        self.inputsNodes = 0\n",
    "        self.next_index = 0\n",
    "        self.lostHist = []\n",
    "        self.x_train = None\n",
    "        self.batch_size = 1   \n",
    "        self.loss = []\n",
    "        self.inputsNodes = inputs\n",
    "        self.x_normalizeScalars = None\n",
    "        self.y_normalizeScalars = None\n",
    "        self.axisToNormalize = (None, None)\n",
    "        self.lossFunction = lossFunction\n",
    "        \n",
    "    def activation(self, activ, z):\n",
    "        if(activ == Activation.SIGMOID):\n",
    "            return self.sigmoid(z)\n",
    "        elif(activ == Activation.SOFTMAX):\n",
    "            return self.softmax(z)\n",
    "        else:\n",
    "            return self.relu(z)\n",
    "            \n",
    "    def activation_derivative(self, activ, z):\n",
    "        if(activ == Activation.SIGMOID):\n",
    "            return self.sigmoid_derivative(z)\n",
    "        elif(activ == Activation.RELU):\n",
    "            return self.relu_derivative(z)\n",
    "        else:\n",
    "            return self.softmax_derivative(z)\n",
    "            \n",
    "    def MSE(self, a, y):\n",
    "        return np.square((y-a))/2  \n",
    "        \n",
    "    def sigmoid(self, z):\n",
    "        return 1/(1 + np.exp(-z))    \n",
    "    \n",
    "    def sigmoid_derivative(self, z):\n",
    "        return self.sigmoid(z) * (1-self.sigmoid(z))\n",
    "    \n",
    "    def relu(self, z):\n",
    "        return np.maximum(z,0)\n",
    "    \n",
    "    def relu_derivative(self, z):\n",
    "        return (z >= 0).astype(int)  \n",
    "    \n",
    "    def softmax(self, z):\n",
    "        return np.exp(z) / np.exp(z).sum(axis=0)\n",
    "    \n",
    "    def softmax_derivative(self, z):\n",
    "        return self.softmax(z) * (1 - self.softmax(z))\n",
    "    \n",
    "    def crossEntropy(self, a, y):\n",
    "        return -np.sum(y * np.log(a), axis = 0)\n",
    "    \n",
    "    def addLayer(self, activation, neurons):\n",
    "        layer = Layer(neurons, activation)\n",
    "        self.layers.append(layer)\n",
    "        \n",
    "    def addInputs(self, inputsCount):\n",
    "        self.inputsNodes = inputsCount\n",
    "        \n",
    "    def set_weights(self, initValue = 1):\n",
    "        for i, layer in enumerate(self.layers):\n",
    "            if i == 0 :\n",
    "                layer.w = np.random.uniform(low=0, high=initValue, size=(self.inputsNodes,layer.neuronsCount()))\n",
    "            else:\n",
    "                layer.w = np.random.uniform(low=0, high=initValue, size=(self.layers[i-1].neuronsCount(),layer.neuronsCount()))\n",
    "            \n",
    "    def evaluateOne(self, x_batch):\n",
    "        for i,l in enumerate(self.layers):\n",
    "            # Logit\n",
    "            if i == 0:\n",
    "                l.z = np.dot(l.w.T, x_batch) + l.b\n",
    "            else:\n",
    "                l.z = np.dot(l.w.T, self.layers[i-1].a) + l.b\n",
    "            # Activation\n",
    "            l.a = self.activation(l.activation, l.z)\n",
    "  \n",
    "\n",
    "    def backpropagation(self, x_batch, y_batch, rate):\n",
    "        for j,l in enumerate(self.layers[::-1]):\n",
    "            i = len(self.layers) - (1 + j)\n",
    "            if i == len(self.layers) -1:\n",
    "                if self.lossFunction == Loss.CE:\n",
    "                    l.delta = l.a - y_batch\n",
    "                else:\n",
    "                    l.delta = l.a - y_batch\n",
    "                l.gradient_w = np.einsum('ij,jk->jik', self.layers[i-1].a, l.delta.T)\n",
    "                l.gradient_w = np.mean(l.gradient_w, axis=0)\n",
    "                l.gradient_b = np.mean(l.delta, axis=1)\n",
    "            elif i == 0:\n",
    "                l.delta = np.multiply(self.activation_derivative(l.activation, l.z), np.dot(self.layers[i+1].w, self.layers[i+1].delta))\n",
    "                l.gradient_w= np.einsum('ij,jk->jik', x_batch, l.delta.T)\n",
    "                l.gradient_w = np.mean(l.gradient_w, axis=0)\n",
    "                l.gradient_b = np.mean(l.delta, axis=1)\n",
    "            else:\n",
    "                l.delta = np.multiply(self.activation_derivative(l.activation, l.z), np.dot(self.layers[i+1].w, self.layers[i+1].delta))\n",
    "                l.gradient_w= np.einsum('ij,jk->jik', self.layers[i-1].a, l.delta.T)\n",
    "                l.gradient_w = np.mean(l.gradient_w, axis=0)\n",
    "                l.gradient_b = np.mean(l.delta, axis=1)\n",
    "            \n",
    "        for l in self.layers:\n",
    "            l.gradient_b = l.gradient_b.reshape(len(l.gradient_b), 1)\n",
    "            l.w -= rate*l.gradient_w\n",
    "            l.b -= rate*l.gradient_b\n",
    "            \n",
    "    def train(self, x_train, y_train, epochs, rate, batch_size = 1):\n",
    "        self.set_weights()        \n",
    "        self.x_train = x_train\n",
    "        self.y_train = y_train   \n",
    "\n",
    "        if self.axisToNormalize[0] != None or self.axisToNormalize[1] != None:\n",
    "            print(\"X normalization : {} | Y normalization : {}\".format(self.axisToNormalize[0], self.axisToNormalize[1]))\n",
    "            self.normalizeBackend(self.axisToNormalize[0], self.axisToNormalize[1])\n",
    "        else :\n",
    "            print(\"[Warning] Data not normalized\")\n",
    "            \n",
    "        self.batch_size = batch_size   \n",
    "        \n",
    "        shuffleTime = int(np.ceil(len(self.x_train)/self.batch_size))        \n",
    "       \n",
    "        for epoch in range(epochs):\n",
    "            idx = np.random.permutation(self.x_train.index)\n",
    "            self.x_train = self.x_train.reindex(idx).reset_index(drop=True, inplace=False)\n",
    "            self.y_train = self.y_train.reindex(idx).reset_index(drop=True, inplace=False)\n",
    "            self.next_index = 0\n",
    "            epochLoss = []            \n",
    "            for it in range(shuffleTime):            \n",
    "                current_index = self.next_index\n",
    "                self.next_index = self.next_index + self.batch_size if self.next_index + self.batch_size < len(self.x_train) - 1 else 0\n",
    "\n",
    "                x_batch = self.x_train.iloc[current_index:].to_numpy().T if self.next_index == 0 else self.x_train.iloc[current_index: self.next_index].to_numpy().T\n",
    "                y_batch = np.vstack(self.y_train.iloc[current_index:].to_numpy()).T if self.next_index == 0 else np.vstack(self.y_train.iloc[current_index:self.next_index].to_numpy()).T        \n",
    "\n",
    "                self.evaluateOne(x_batch)\n",
    "                \n",
    "                if self.lossFunction == Loss.CE:\n",
    "                    loss = np.mean(self.crossEntropy(self.layers[-1].a, y_batch))\n",
    "                else:\n",
    "                    loss = np.mean(self.MSE(self.layers[-1].a, y_batch))    \n",
    "                    \n",
    "                epochLoss.append(loss)\n",
    "                self.backpropagation(x_batch, y_batch, rate)\n",
    "            if(epoch% 100 == 0 or epoch == epochs-1):\n",
    "                print(\"Epoch {} / {} - Loss : {}\".format(epoch+1, epochs, np.mean(epochLoss)))\n",
    "            self.loss.append(np.mean(epochLoss))\n",
    "            \n",
    "    def normalizeBackend(self, x, y):\n",
    "        if x is True:\n",
    "            self.x_normalizeScalars = (self.x_train.min(axis=0), self.x_train.max(axis=0))\n",
    "            self.x_train = (self.x_train - self.x_normalizeScalars[0]) / (self.x_normalizeScalars[1] - self.x_normalizeScalars[0])\n",
    "        if y is True:\n",
    "            self.y_normalizeScalars = (self.y_train.min(axis=0), self.y_train.max(axis=0))\n",
    "            self.y_train = (self.y_train - self.y_normalizeScalars[0]) / (self.y_normalizeScalars[1] - self.y_normalizeScalars[0])\n",
    "            \n",
    "    def normalize(self, x=True, y=False):\n",
    "        self.axisToNormalize = (x,y)\n",
    "    \n",
    "    def predict(self, x_batch, returnValue = False):\n",
    "        if self.axisToNormalize[0] != None:\n",
    "            print(\"X normalization : {} \".format(self.axisToNormalize[0]))\n",
    "            x_batch = (x_batch - self.x_normalizeScalars[0]) / (self.x_normalizeScalars[1] - self.x_normalizeScalars[0])\n",
    "        x_batch_T = x_batch.to_numpy().T\n",
    "        self.evaluateOne( x_batch_T)\n",
    "        if returnValue:\n",
    "            return self.layers[-1].a\n",
    "        else:\n",
    "            pass\n",
    "    \n",
    "    def test(self, y, y_pred = None):\n",
    "        y_original = y.copy()\n",
    "        y_original = np.stack(y_original.to_numpy()).T\n",
    "\n",
    "        if(y_pred == None):\n",
    "            y_pred = self.layers[-1].a\n",
    "        # Transpose Y (observations in columns)\n",
    "        if self.axisToNormalize[1] is True:\n",
    "            print(\"Y normalization : {} \".format(self.axisToNormalize[1]))\n",
    "            y = (y - self.y_normalizeScalars[0]) / (self.y_normalizeScalars[1] - self.y_normalizeScalars[0])\n",
    "        y = np.stack(y.to_numpy()).T\n",
    "        \n",
    "        if self.lossFunction == Loss.CE:\n",
    "            # Good prediciton rate\n",
    "            max_indices = np.argmax(y_pred, axis=0)\n",
    "            matching_counts = np.sum(y[max_indices, np.arange(y_pred.shape[1])])\n",
    "            print(\"Good prediction : {}/{} | {}%\".format(matching_counts, len(max_indices), (matching_counts * 100) / len(max_indices)))\n",
    "            print(\"Loss : {}\\n\".format(np.mean(self.crossEntropy(y_pred, y))))\n",
    "        else:\n",
    "\n",
    "            df_test = pd.DataFrame({'Ypred': y_pred[0], 'YobsNormalized': y})\n",
    "            df_test[\"difNormalized\"] = y_pred[0] - y\n",
    "            df_test[\"YpredDeNormalized\"] = y_pred[0] * (self.y_normalizeScalars[1] -self.y_normalizeScalars[0]) + self.y_normalizeScalars[0]\n",
    "            df_test[\"Yobs\"] = y_original\n",
    "            df_test[\"difDeNormalized\"] = df_test[\"YpredDeNormalized\"] - df_test[\"Yobs\"]\n",
    "            df_test[\"loss\"] = self.MSE(y_pred, y)[0]            \n",
    "            display(df_test)\n",
    "            print(\"Loss : {}\\n\".format(np.mean(self.MSE(y_pred, y))))\n",
    "        # Plot loss over epochs\n",
    "        plt.plot(model.loss)\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.title('Loss over epochs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6907ce63-89e1-4789-b34a-8778f8850db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "np.set_printoptions(linewidth=np.inf)\n",
    "\n",
    "def combine_to_list(row):\n",
    "    return np.array([row['Iris-setosa'], row['Iris-versicolor'], row['Iris-virginica']])\n",
    "\n",
    "# Load csv\n",
    "df = pd.read_csv(\"iris_csv.csv\")\n",
    "\n",
    "# One hot econding class\n",
    "classCols = pd.get_dummies(df['class'], prefix='', prefix_sep='')\n",
    "df = pd.concat([df, classCols.apply(combine_to_list, axis = 1)], axis=1)\n",
    "df.drop(['class'], axis=1, inplace=True)\n",
    "\n",
    "# shuffle before split\n",
    "df = df.sample(frac = 1).reset_index(drop=True, inplace=False)\n",
    "\n",
    "# Split train/test\n",
    "msk = np.random.rand(len(df)) < 0.8\n",
    "train, test = df[msk], df[~msk]\n",
    "train.reset_index(drop=True, inplace=True)\n",
    "test.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Split training data between X and Y\n",
    "y_train = train[0]\n",
    "x_train = train.iloc[:, :-1]\n",
    "\n",
    "# (split like this for a regresion task)\n",
    "#x_test = test[[\"sepallength\", \"sepalwidth\", \"petalwidth\"]]\n",
    "#y_test = test.petallength\n",
    "\n",
    "# Split test data between X and Y\n",
    "y_test = test[0]\n",
    "x_test = test.iloc[:, :-1]\n",
    "\n",
    "# (split like this for a regresion task)\n",
    "#y_test = test.petallength\n",
    "#x_test = test[[\"sepallength\", \"sepalwidth\", \"petalwidth\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "21e3ac30-e1bc-4d6a-8705-a478065a610b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X normalization : True | Y normalization : False\n",
      "Epoch 1 / 10000 - Loss : 1.1664473481940847\n",
      "Epoch 101 / 10000 - Loss : 1.0524697916955996\n",
      "Epoch 201 / 10000 - Loss : 0.9095127619228103\n",
      "Epoch 301 / 10000 - Loss : 0.6855798965500921\n",
      "Epoch 401 / 10000 - Loss : 0.5613972007549961\n",
      "Epoch 501 / 10000 - Loss : 0.495954520573204\n",
      "Epoch 601 / 10000 - Loss : 0.448347342022461\n",
      "Epoch 701 / 10000 - Loss : 0.40566887961410064\n",
      "Epoch 801 / 10000 - Loss : 0.36482131063151935\n",
      "Epoch 901 / 10000 - Loss : 0.32594854275424984\n",
      "Epoch 1001 / 10000 - Loss : 0.2889596797912752\n",
      "Epoch 1101 / 10000 - Loss : 0.25517485858690525\n",
      "Epoch 1201 / 10000 - Loss : 0.22480278635391868\n",
      "Epoch 1301 / 10000 - Loss : 0.19829485379382208\n",
      "Epoch 1401 / 10000 - Loss : 0.17577134713772286\n",
      "Epoch 1501 / 10000 - Loss : 0.1569952860971588\n",
      "Epoch 1601 / 10000 - Loss : 0.14142019512760723\n",
      "Epoch 1701 / 10000 - Loss : 0.12870893259965516\n",
      "Epoch 1801 / 10000 - Loss : 0.11789760036180778\n",
      "Epoch 1901 / 10000 - Loss : 0.10909666134315983\n",
      "Epoch 2001 / 10000 - Loss : 0.10157155351153922\n",
      "Epoch 2101 / 10000 - Loss : 0.09538235767804157\n",
      "Epoch 2201 / 10000 - Loss : 0.0900727288650476\n",
      "Epoch 2301 / 10000 - Loss : 0.08539696335565326\n",
      "Epoch 2401 / 10000 - Loss : 0.08127973051509754\n",
      "Epoch 2501 / 10000 - Loss : 0.07807914266334162\n",
      "Epoch 2601 / 10000 - Loss : 0.07473102031379777\n",
      "Epoch 2701 / 10000 - Loss : 0.0721457673279006\n",
      "Epoch 2801 / 10000 - Loss : 0.06973045798822562\n",
      "Epoch 2901 / 10000 - Loss : 0.06735622275783715\n",
      "Epoch 3001 / 10000 - Loss : 0.06551309948422117\n",
      "Epoch 3101 / 10000 - Loss : 0.06384406771902996\n",
      "Epoch 3201 / 10000 - Loss : 0.062255570363993984\n",
      "Epoch 3301 / 10000 - Loss : 0.06094783430596631\n",
      "Epoch 3401 / 10000 - Loss : 0.05954980676274756\n",
      "Epoch 3501 / 10000 - Loss : 0.058289175369202056\n",
      "Epoch 3601 / 10000 - Loss : 0.05721598523012725\n",
      "Epoch 3701 / 10000 - Loss : 0.056062610361985926\n",
      "Epoch 3801 / 10000 - Loss : 0.05514853044408053\n",
      "Epoch 3901 / 10000 - Loss : 0.054224340592860985\n",
      "Epoch 4001 / 10000 - Loss : 0.053376470715567115\n",
      "Epoch 4101 / 10000 - Loss : 0.05251296635374817\n",
      "Epoch 4201 / 10000 - Loss : 0.05176285236702134\n",
      "Epoch 4301 / 10000 - Loss : 0.05090830415275831\n",
      "Epoch 4401 / 10000 - Loss : 0.05044105260038391\n",
      "Epoch 4501 / 10000 - Loss : 0.04985725270556404\n",
      "Epoch 4601 / 10000 - Loss : 0.04922276077009025\n",
      "Epoch 4701 / 10000 - Loss : 0.04863241245972944\n",
      "Epoch 4801 / 10000 - Loss : 0.04808725921418799\n",
      "Epoch 4901 / 10000 - Loss : 0.04763726600247387\n",
      "Epoch 5001 / 10000 - Loss : 0.047169243927350536\n",
      "Epoch 5101 / 10000 - Loss : 0.04668579470345052\n",
      "Epoch 5201 / 10000 - Loss : 0.04635122941437839\n",
      "Epoch 5301 / 10000 - Loss : 0.04582320695613645\n",
      "Epoch 5401 / 10000 - Loss : 0.04540417708887858\n",
      "Epoch 5501 / 10000 - Loss : 0.045046450771226765\n",
      "Epoch 5601 / 10000 - Loss : 0.04461012669925248\n",
      "Epoch 5701 / 10000 - Loss : 0.04443310271906907\n",
      "Epoch 5801 / 10000 - Loss : 0.04396743216058\n",
      "Epoch 5901 / 10000 - Loss : 0.04366052676860304\n",
      "Epoch 6001 / 10000 - Loss : 0.043338266679130565\n",
      "Epoch 6101 / 10000 - Loss : 0.04303381545645395\n",
      "Epoch 6201 / 10000 - Loss : 0.04262907274667723\n",
      "Epoch 6301 / 10000 - Loss : 0.04249630168026135\n",
      "Epoch 6401 / 10000 - Loss : 0.04223558221221679\n",
      "Epoch 6501 / 10000 - Loss : 0.04179134070479622\n",
      "Epoch 6601 / 10000 - Loss : 0.04170103588908729\n",
      "Epoch 6701 / 10000 - Loss : 0.04117245129763072\n",
      "Epoch 6801 / 10000 - Loss : 0.041046104798506976\n",
      "Epoch 6901 / 10000 - Loss : 0.04087069312036323\n",
      "Epoch 7001 / 10000 - Loss : 0.040666751496744806\n",
      "Epoch 7101 / 10000 - Loss : 0.04028151773219673\n",
      "Epoch 7201 / 10000 - Loss : 0.04005314036263539\n",
      "Epoch 7301 / 10000 - Loss : 0.03992692875666335\n",
      "Epoch 7401 / 10000 - Loss : 0.03971982739783089\n",
      "Epoch 7501 / 10000 - Loss : 0.039397165141454936\n",
      "Epoch 7601 / 10000 - Loss : 0.039121445858780426\n",
      "Epoch 7701 / 10000 - Loss : 0.03893180841862811\n",
      "Epoch 7801 / 10000 - Loss : 0.03894223018936818\n",
      "Epoch 7901 / 10000 - Loss : 0.038534786122857725\n",
      "Epoch 8001 / 10000 - Loss : 0.03870201322942418\n",
      "Epoch 8101 / 10000 - Loss : 0.038397197769241206\n",
      "Epoch 8201 / 10000 - Loss : 0.03825981886457089\n",
      "Epoch 8301 / 10000 - Loss : 0.03767642605401142\n",
      "Epoch 8401 / 10000 - Loss : 0.037635317253733674\n",
      "Epoch 8501 / 10000 - Loss : 0.03789321041526143\n",
      "Epoch 8601 / 10000 - Loss : 0.03755070172078965\n",
      "Epoch 8701 / 10000 - Loss : 0.03703396016618606\n",
      "Epoch 8801 / 10000 - Loss : 0.03702798357646521\n",
      "Epoch 8901 / 10000 - Loss : 0.037055182057551095\n",
      "Epoch 9001 / 10000 - Loss : 0.036703945246435256\n",
      "Epoch 9101 / 10000 - Loss : 0.036749463561187724\n",
      "Epoch 9201 / 10000 - Loss : 0.03633486708193625\n",
      "Epoch 9301 / 10000 - Loss : 0.03646659920319845\n",
      "Epoch 9401 / 10000 - Loss : 0.03637490597018729\n",
      "Epoch 9501 / 10000 - Loss : 0.03623657201596965\n",
      "Epoch 9601 / 10000 - Loss : 0.03604131939240274\n",
      "Epoch 9701 / 10000 - Loss : 0.0356372832103846\n",
      "Epoch 9801 / 10000 - Loss : 0.035518907815979134\n",
      "Epoch 9901 / 10000 - Loss : 0.03579659493631583\n",
      "Epoch 10000 / 10000 - Loss : 0.035774367955454446\n"
     ]
    }
   ],
   "source": [
    "model = FNN(Loss.CE, inputs = 4)\n",
    "model.normalize(x = True, y = False)\n",
    "model.addLayer(Activation.SIGMOID, neurons = 3)\n",
    "model.addLayer(Activation.SOFTMAX, neurons = 3)\n",
    "model.train(x_train, y_train, epochs = 10000, rate = .01, batch_size = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "45dd5068-d356-4e28-96bc-da3a321ec662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X normalization : True \n"
     ]
    }
   ],
   "source": [
    "model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "356f2f4a-1e1b-44f9-acde-8ae6f92dd849",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good prediction : 34/35 | 97.14285714285714%\n",
      "Loss : 0.09386245487682048\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.test(y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
